{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJOYzMvBQ3lZ"
      },
      "source": [
        "# Imports, Drive and GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To8bxiHdQVfV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # dataframes\n",
        "import numpy as np # vectors and matrixes\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedGroupKFold # cross-validation\n",
        "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit # separate train and test sets\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, auc, f1_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns # for confusion matrix\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt # plots\n",
        "from sklearn.preprocessing import MinMaxScaler # normalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.models import load_model\n",
        "from statistics import mean, stdev\n",
        "import math\n",
        "from scipy.ndimage import zoom # resize scans and attention maps\n",
        "import copy\n",
        "from keras import Model # intermediate layer (fature extraction)\n",
        "# eliminate ramdomness to get reproducible results\n",
        "import os # to create directories\n",
        "os.environ['PYTHONHASHSEED']=str(7)\n",
        "import random\n",
        "random.seed(7)\n",
        "from numpy.random import seed\n",
        "seed(7)\n",
        "tf.random.set_seed(7)\n",
        "# to compute elapsed time of training\n",
        "import time \n",
        "from datetime import timedelta\n",
        "from tensorflow.keras.optimizers import SGD # to select sgd optimizer\n",
        "from requests import get # to get this Google Colab file name\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import collections # for verifies\n",
        "import shutil # to move files from directories\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import json # for serialization\n",
        "from contextlib import redirect_stdout # to redirect the standard output to a file (print model summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc211_D6qsjK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files # to use Google Drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive/') # connect to Google Drive\n",
        "root_path = '/content/drive/My Drive/dataset' # change directory to my Google Drive\n",
        "#root_path = 'G:\\My Drive\\dataset' # change directory to my device's database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRaQG0H_8_vI"
      },
      "source": [
        "Create directory for model metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjJDu16G85XU"
      },
      "outputs": [],
      "source": [
        "model_name = '/ROI/'+get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n",
        "model_name = model_name[:len(model_name)-6]\n",
        "model_name = model_name.replace('%20', ' ')\n",
        "print(model_name)\n",
        "if not os.path.exists(root_path+'/Models_metrics'+ model_name):\n",
        "    os.makedirs(root_path+'/Models_metrics'+ model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CECgYGUuTKn"
      },
      "source": [
        "Save GPU name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dtVy_VJXRH61",
        "outputId": "3330fdb6-6ec7-4e64-e907-1a001729741c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/dataset/Models_metrics/ROI/Python ResNet18 ROI input/gpu_name.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "if os.path.isfile('/gpu_name.txt'):\n",
        "  print('exists in the destination path!')\n",
        "  os.remove('/gpu_name.txt')\n",
        "!nvidia-smi -L >> gpu_name.txt\n",
        "if os.path.isfile(root_path+'/Models_metrics'+ model_name+'/gpu_name.txt'):\n",
        "  print('exists in the destination path!')\n",
        "  os.remove(root_path+'/Models_metrics'+ model_name+'/gpu_name.txt')\n",
        "shutil.move('gpu_name.txt', root_path+'/Models_metrics'+ model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HYntZ16MApn"
      },
      "source": [
        "# Setting Scan IDs, Subjects IDs and Scan Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-ZikUVSJ-UF"
      },
      "source": [
        "scan_ids - Identification of each scan\n",
        "\n",
        "labels - dictionary (key - scan ID; value - ground truth label)\n",
        "\n",
        "subject_id - dictionary (key - scan ID; value - subject id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BweTjZSbCla7"
      },
      "outputs": [],
      "source": [
        "# set a list with all the scan ids possible\n",
        "task = \"NC vs AD\" # (\"NC vs AD\" \"AD vs MCI\" \"NC vs MCI\" \"NC vs MCI vs AD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "im8sNsPNES_D"
      },
      "outputs": [],
      "source": [
        "data_augmentation = 0\n",
        "if data_augmentation == 1:\n",
        "  pet_source = '/PETs_numpy_data_augmentation'\n",
        "else:\n",
        "  pet_source = '/PETs_numpy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSF23-4sNFLe"
      },
      "outputs": [],
      "source": [
        "# load labels\n",
        "labels = np.load(root_path + pet_source + '/Labels/labels.npy', allow_pickle='TRUE')\n",
        "labels = labels.item()\n",
        "# load subject ids\n",
        "subject_id = np.load(root_path + pet_source + '/Subject_id/subject_id.npy', allow_pickle='TRUE')\n",
        "subject_id = subject_id.item() # it is a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-0SY9QqAx0h"
      },
      "outputs": [],
      "source": [
        "nr_classes = 2\n",
        "if task == \"NC vs AD\":\n",
        "  # remove MCI information\n",
        "  labels = { key: val for key, val in labels.items() if val != 1}\n",
        "  scan_ids = list(labels.keys())\n",
        "  subject_id = { key: val for key, val in subject_id.items() if key in scan_ids }\n",
        "  # the class of AD is represented by nr 2, but we have to set it to 1 to be adapted for the model\n",
        "  labels = {x: 1 if labels[x] == 2 else labels[x] for x in labels }\n",
        "  target_classes = ['NC', 'AD']\n",
        "elif task == \"AD vs MCI\":\n",
        "  # remove NC information\n",
        "  labels = { key: val for key, val in labels.items() if val != 0}\n",
        "  scan_ids = list(labels.keys())\n",
        "  subject_id = { key: val for key, val in subject_id.items() if key in scan_ids }\n",
        "  # the class of AD is represented by nr 2, but we have to set it to 0 to be adapted for the model\n",
        "  labels = {x: 0 if labels[x] == 2 else labels[x] for x in labels }\n",
        "  target_classes = ['AD', 'MCI']\n",
        "elif task == \"NC vs MCI\":\n",
        "  # remove AD information\n",
        "  labels = { key: val for key, val in labels.items() if val != 2}\n",
        "  scan_ids = list(labels.keys())\n",
        "  subject_id = { key: val for key, val in subject_id.items() if key in scan_ids }\n",
        "  target_classes = ['NC', 'MCI']\n",
        "elif task == \"NC vs MCI vs AD\":\n",
        "  scan_ids = list(labels.keys())\n",
        "  nr_classes = 3\n",
        "  target_classes = ['NC', 'MCI', 'AD']\n",
        "\n",
        "# list with all the labels, alternative to dictionary (needed sometimes)\n",
        "labels_list = [ labels[id] for id in scan_ids ]\n",
        "# list with all the subjects ids, alternative to dictionary (needed sometimes)\n",
        "subject_id_list = [ subject_id[id] for id in scan_ids  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lok_sHRz4kDz"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjxl0ddPzG5N"
      },
      "source": [
        "Auxilary function to transform from 2D coordinates to 1D and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAs-7WyWzFDa"
      },
      "outputs": [],
      "source": [
        "def coordinates_transform(point_vector_form):\n",
        "  fixation_image = np.zeros(128*128)\n",
        "  fixation_image[point_vector_form] = 1\n",
        "  fixation_image = fixation_image.reshape(128, 128)\n",
        "  coord_point = np.nonzero(fixation_image)\n",
        "  return coord_point\n",
        "\n",
        "def coordinates_untransform(point_x, point_y):\n",
        "  if 0 <= point_x <= 127 and 0 <= point_y <= 127: \n",
        "    pt = 128*point_x+point_y\n",
        "    return pt\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeq-jZRBzTVM"
      },
      "outputs": [],
      "source": [
        "# plot the scan\n",
        "def show_scan_plot(scan, slice_nr):\n",
        "  one_slice_2d = scan[:,:,slice_nr] # array with one slice of a single patient\n",
        "  plt.imshow(one_slice_2d, cmap='jet')\n",
        "  plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt9ClijKyr5m"
      },
      "source": [
        "Plot a slice of a scan with the corresponding fixations on top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XFixVxgypjb"
      },
      "outputs": [],
      "source": [
        "# plot the fixations on top of the scan\n",
        "def show_scan_with_fixations(allData, slice_nr, scan_index, save):\n",
        "\n",
        "  if allData.at[scan_index, 'Has Fix'] == 0 or allData.at[scan_index, 'Fixations'][slice_nr] == []: \n",
        "    print(\"There are no fixations for slice number \", slice_nr, \" of scan on row \", scan_index)\n",
        "    return\n",
        "\n",
        "  print(\"Subject \", allData.at[scan_index, 'Subject ID'])\n",
        "  print(\"Fixation points \", allData.at[scan_index, 'Durations'][slice_nr])\n",
        "\n",
        "  one_slice_2d = copy.deepcopy(allData.at[scan_index, 'Scan'][:,:,slice_nr]) # array with one slice of a single patient\n",
        "  \n",
        "  plt.imshow(one_slice_2d, cmap='jet')\n",
        "  plt.colorbar()\n",
        "\n",
        "  locations = allData.at[scan_index, 'Fixations'][slice_nr]\n",
        "  coord = coordinates_transform(locations)\n",
        "  plt.scatter(coord[0], coord[1])\n",
        "  \n",
        "  if save == \"save\":\n",
        "    plt.savefig(f\"/content/drive/My Drive/plots/scan_fixations_{allData.at[scan_index, 'Class']}_{slice_nr}_{allData.at[scan_index, 'Subject ID']}.pdf\", \n",
        "              bbox_inches =\"tight\")\n",
        "  \n",
        "  #plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj5LXtMvm2vk"
      },
      "source": [
        "# Verification of correct process of stratified cross-validation (To use when programming)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H613t1rEzVih"
      },
      "source": [
        "Print the number of scans of a subject in the train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI8qqQbEm2Pu"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "def print_scans_of_the_same_subject(subject_id, train_scans, test_scans):\n",
        "  subjects_train = [ subject_id[scan] for scan in train_scans ]\n",
        "  print(\"subject \", subject_id, \" has \", collections.Counter(subjects_train), \" in the train dataset\")\n",
        "\n",
        "  subjects_test = [ subject_id[scan] for scan in test_scans ]\n",
        "  print(\"subject \", subject_id, \" has \", collections.Counter(subjects_test), \" in the test dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBIsDvQNzV9F"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jflw6Bs0nA1U"
      },
      "outputs": [],
      "source": [
        "def verify_veracity(index, subject_id_list, scan_ids, labels_list):\n",
        "  print(\"subject id \", subject_id_list[index])\n",
        "  print(\"scan \", scan_ids[index])\n",
        "  print(\"label \", labels_list[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3ZrFwUizWeK"
      },
      "source": [
        "Print list of subjects IDs for both classes (there cannot be an overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm2E12AMnCXt"
      },
      "outputs": [],
      "source": [
        "def verify_common_subjects(subject_id, train_scans, test_scans):\n",
        "  subjects_train = [ subject_id[scan] for scan in train_scans ]\n",
        "  print(subjects_train)\n",
        "  subjects_test = [ subject_id[scan] for scan in test_scans ]\n",
        "  print(subjects_test)\n",
        "  common_items = [ item for item in subjects_test if item in subjects_train ]\n",
        "  print(common_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSFR6l8wzXLS"
      },
      "source": [
        "Check the porportion of both classes in the train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQeSGVB7nD13"
      },
      "outputs": [],
      "source": [
        "def verify_proportions(labels, train, test):\n",
        "  train_total = 0\n",
        "  train_count_class1 = 0\n",
        "  train_count_class2 = 0\n",
        "\n",
        "  for scan_id in train:\n",
        "    train_total +=1\n",
        "    if labels[scan_id] == 0:\n",
        "      train_count_class1 +=1\n",
        "    else:\n",
        "      train_count_class2 +=1\n",
        "\n",
        "  print(\"Train class1: \", round(train_count_class1/train_total, 2) ,\"class2: \", round(train_count_class2/train_total, 2))\n",
        "\n",
        "  test_total = 0\n",
        "  test_count_class1 = 0\n",
        "  test_count_class2 = 0\n",
        "\n",
        "  for scan_id in test:\n",
        "    test_total +=1\n",
        "    if labels[scan_id] == 0:\n",
        "      test_count_class1 +=1\n",
        "    else:\n",
        "      test_count_class2 +=1\n",
        "\n",
        "  print(\"Test class1: \", round(test_count_class1/test_total, 2) ,\"class2: \", round(test_count_class2/test_total, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_5dmmdZaYTb"
      },
      "source": [
        "# Single fixed saliency map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FFi_fQ0aU49"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    GlobalAveragePooling3D, \n",
        "    GlobalMaxPooling3D, \n",
        "    Reshape, \n",
        "    Dense, \n",
        "    multiply, \n",
        "    Permute, \n",
        "    Concatenate, \n",
        "    Conv2D, Add, Activation, Lambda\n",
        ")\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "\n",
        "class att(layers.Layer):\n",
        "\tdef __init__(self, name, **kwargs):\n",
        "\t\tsuper(att, self).__init__(name=name, **kwargs)\n",
        "\n",
        "\tdef call(self, cbam_feature):\n",
        "\t\tsize_1 = cbam_feature.shape[DIM1_AXIS]\n",
        "\t\tsize_2 = cbam_feature.shape[DIM2_AXIS]\n",
        "\t\tsize_3 = cbam_feature.shape[DIM3_AXIS]\n",
        "\n",
        "\t\tatt_map = np.zeros((1, size_1, size_2, size_3, 1))\n",
        "\t\tatt_map[0,:,:,:,0] = np.load(root_path + '/ROI/ROIs_with_64axial_slices_binary.npy')[:,:,0:60]\n",
        "\t\treturn att_map\n",
        "\n",
        "# not CBAM - provides only the resized fixed attention maps already created\n",
        "def cbam_block(cbam_feature):\n",
        "\n",
        "\tatt_map = att(name=\"att\"+\"_\"+str(cbam_block.att_layer_nr))(cbam_feature)\n",
        "\tassert att_map.shape[-1] == 1\n",
        "\tcbam_block.att_layer_nr += 1\n",
        "\n",
        "\treturn multiply([cbam_feature, att_map])\n",
        "cbam_block.att_layer_nr = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8qEidKDQ7nf"
      },
      "source": [
        "# ResNet 3D from Jihong Ju"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2fT5uTBJ74N"
      },
      "source": [
        "3D ResNet that accepts as input 3D arrays with multiple channels. PET scans are 3D arrays with one channel.\n",
        "\n",
        "This code was retrived from https://github.com/JihongJu/keras-resnet3d/blob/master/resnet3d/resnet3d.py with minor adaptations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMp-0J5hOzDJ"
      },
      "outputs": [],
      "source": [
        "from __future__ import (\n",
        "    absolute_import,\n",
        "    division,\n",
        "    print_function,\n",
        "    unicode_literals\n",
        ")\n",
        "import six\n",
        "import math\n",
        "from math import ceil\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten\n",
        ")\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv3D,\n",
        "    AveragePooling3D,\n",
        "    MaxPooling3D\n",
        ")\n",
        "from tensorflow.keras.layers import add\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "## Resnet 3D architecture\n",
        "\n",
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block (by @raghakot).\"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS, momentum=0.99)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "def _conv_bn_relu3D(**conv_params):\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\n",
        "        \"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
        "                                                l2(1e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv3D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, kernel_initializer=kernel_initializer,\n",
        "                      padding=padding,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "def _bn_relu_conv3d(**conv_params):\n",
        "    \"\"\"Helper to build a  BN -> relu -> conv3d block.\"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\",\n",
        "                                                \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
        "                                                l2(1e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        block = Conv3D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, kernel_initializer=kernel_initializer,\n",
        "                      padding=padding,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "        return block\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut3d(input, residual):\n",
        "    \"\"\"3D shortcut to match input and residual and merges them with \"sum\".\"\"\"\n",
        "    stride_dim1 = math.ceil(int(input.shape[DIM1_AXIS]) \\\n",
        "        / int(residual.shape[DIM1_AXIS]))\n",
        "    stride_dim2 = math.ceil(int(input.shape[DIM2_AXIS]) \\\n",
        "        / int(residual.shape[DIM2_AXIS]))\n",
        "    stride_dim3 = math.ceil(int(input.shape[DIM3_AXIS]) \\\n",
        "        / int(residual.shape[DIM3_AXIS]))\n",
        "    equal_channels = int(residual.shape[CHANNEL_AXIS]) \\\n",
        "        == int(input.shape[CHANNEL_AXIS])\n",
        "\n",
        "    shortcut = input\n",
        "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 \\\n",
        "            or not equal_channels:\n",
        "        shortcut = Conv3D(\n",
        "            filters=int(residual.shape[CHANNEL_AXIS]),\n",
        "            kernel_size=(1, 1, 1),\n",
        "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
        "            kernel_initializer=\"he_normal\", padding=\"valid\",\n",
        "            kernel_regularizer=l2(1e-4)\n",
        "            )(input)\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block3d(block_function, filters, kernel_regularizer, repetitions,\n",
        "                      is_first_layer=False):\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            strides = (1, 1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                strides = (2, 2, 2)\n",
        "            input = block_function(filters=filters, strides=strides,\n",
        "                                   kernel_regularizer=kernel_regularizer,\n",
        "                                   is_first_block_of_first_layer=(\n",
        "                                       is_first_layer and i == 0)\n",
        "                                   )(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
        "                is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
        "    def f(input):\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n",
        "                           strides=strides, padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=kernel_regularizer\n",
        "                           )(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv3d(filters=filters,\n",
        "                                    kernel_size=(3, 3, 3),\n",
        "                                    strides=strides,\n",
        "                                    kernel_regularizer=kernel_regularizer\n",
        "                                    )(input)\n",
        "\n",
        "        residual = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
        "                                   kernel_regularizer=kernel_regularizer\n",
        "                                   )(conv1)\n",
        "        return _shortcut3d(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
        "               is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
        "    def f(input):\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv3D(filters=filters, kernel_size=(1, 1, 1),\n",
        "                              strides=strides, padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=kernel_regularizer\n",
        "                              )(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv3d(filters=filters, kernel_size=(1, 1, 1),\n",
        "                                       strides=strides,\n",
        "                                       kernel_regularizer=kernel_regularizer\n",
        "                                       )(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
        "                                   kernel_regularizer=kernel_regularizer\n",
        "                                   )(conv_1_1)\n",
        "        residual = _bn_relu_conv3d(filters=filters * 4, kernel_size=(1, 1, 1),\n",
        "                                   kernel_regularizer=kernel_regularizer\n",
        "                                   )(conv_3_3)\n",
        "\n",
        "        return _shortcut3d(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_data_format():\n",
        "    global DIM1_AXIS\n",
        "    global DIM2_AXIS\n",
        "    global DIM3_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        print(\"here CHANNELS last\")\n",
        "        DIM1_AXIS = 1\n",
        "        DIM2_AXIS = 2\n",
        "        DIM3_AXIS = 3\n",
        "        CHANNEL_AXIS = 4\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        DIM1_AXIS = 2\n",
        "        DIM2_AXIS = 3\n",
        "        DIM3_AXIS = 4\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class Resnet3DBuilder(object):\n",
        "    \"\"\"ResNet3D.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
        "        \"\"\"Instantiate a vanilla ResNet3D keras model.\n",
        "        # Arguments\n",
        "            input_shape: Tuple of input shape in the format\n",
        "            (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'\n",
        "            (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n",
        "            num_outputs: The number of outputs at the final softmax layer\n",
        "            block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n",
        "            repetitions: Repetitions of unit blocks\n",
        "        # Returns\n",
        "            model: a 3D ResNet model that takes a 5D tensor (volumetric images\n",
        "            in batch) as input and returns a 1D vector (prediction) as output.\n",
        "        \"\"\"\n",
        "        _handle_data_format()\n",
        "        if len(input_shape) != 4:\n",
        "            raise ValueError(\"Input shape should be a tuple \"\n",
        "                             \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
        "                             \"for tensorflow as backend or \"\n",
        "                             \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
        "                             \"for theano as backend\")\n",
        "\n",
        "        block_fn = _get_block(block_fn)\n",
        "        input = Input(shape=input_shape)\n",
        "        input2 = cbam_block(input)\n",
        "        # first conv\n",
        "        conv1 = _conv_bn_relu3D(filters=64, kernel_size=(7, 7, 7),\n",
        "                                strides=(2, 2, 2),\n",
        "                                kernel_regularizer=l2(reg_factor)\n",
        "                                )(input2)\n",
        "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2),\n",
        "                             padding=\"same\")(conv1)\n",
        "\n",
        "        # repeat blocks\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block3d(block_fn, filters=filters,\n",
        "                                      kernel_regularizer=l2(reg_factor),\n",
        "                                      repetitions=r, is_first_layer=(i == 0)\n",
        "                                      )(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # last activation\n",
        "        block_output = _bn_relu(block)\n",
        "\n",
        "        # average poll and classification\n",
        "        pool2 = AveragePooling3D(pool_size=(int(block.shape[DIM1_AXIS]),\n",
        "                                            int(block.shape[DIM2_AXIS]),\n",
        "                                            int(block.shape[DIM3_AXIS])),\n",
        "                                 strides=(1, 1, 1))(block_output)\n",
        "        flatten1 = Flatten()(pool2)\n",
        "        if num_outputs > 1:\n",
        "            dense = Dense(units=num_outputs,\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          activation=\"softmax\",\n",
        "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
        "        else:\n",
        "            dense = Dense(units=num_outputs,\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          activation=\"sigmoid\",\n",
        "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
        "\n",
        "        model = Model(inputs=input, outputs=dense)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs, reg_factor=1e-4):\n",
        "        \"\"\"Build resnet 18.\"\"\"\n",
        "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
        "                                     [2,2,2,2], reg_factor=reg_factor)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs, reg_factor=1e-4):\n",
        "        \"\"\"Build resnet 34.\"\"\"\n",
        "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
        "                                     [3, 4, 6, 3], reg_factor=reg_factor)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs, reg_factor=1e-4):\n",
        "        \"\"\"Build resnet 50.\"\"\"\n",
        "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
        "                                     [3, 4, 6, 3], reg_factor=reg_factor)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs, reg_factor=1e-4):\n",
        "        \"\"\"Build resnet 101.\"\"\"\n",
        "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
        "                                     [3, 4, 23, 3], reg_factor=reg_factor)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs, reg_factor=1e-4):\n",
        "        \"\"\"Build resnet 152.\"\"\"\n",
        "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
        "                                     [3, 8, 36, 3], reg_factor=reg_factor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xKhuepTZoRl"
      },
      "source": [
        "# Data Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNGxnmI1KJo6"
      },
      "source": [
        "All data does not fit in memory during training, therefore a data generator is used. An instance of this data generator transfers to memory a small amount of samples each time, so the model can train with that small amount of samples. In the next iteration, transfers the next set of samples and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ovh4NMnZsLA"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, labels, batch_size=32, dim=(128,128,60), n_channels=1,\n",
        "                 n_classes=2, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            X[i,] = np.load(root_path + pet_source + '/python_normalized_reshaped/' + str(ID) + '.npy')\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels[ID]\n",
        "\n",
        "        if self.n_classes > 1:\n",
        "          y = tf.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT0QCACvqeGx"
      },
      "source": [
        "# Testing Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5cF-DkBqq5C"
      },
      "source": [
        "Metrics: accuracy, confusion matrix, sensistivity, specificity, ROC, AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BS-BD-fvmSN"
      },
      "outputs": [],
      "source": [
        "# only for multiclass classification\n",
        "def plot_ROC_AUC_multiclass(y_true,  y_pred, iteration):\n",
        "\n",
        "  # roc curve for classes\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "\n",
        "  for i in range(nr_classes):\n",
        "      fpr[i], tpr[i], _ = roc_curve(y_true, y_pred, pos_label=i)\n",
        "  \n",
        "  y_true = label_binarize(y_true, classes=[0, 1, 2])\n",
        "  y_pred = label_binarize(y_pred, classes=[0, 1, 2])\n",
        "  auc = roc_auc_score(y_true, y_pred, multi_class=\"ovr\", average=None)\n",
        "      \n",
        "  # plotting\n",
        "  plt.rcParams.update(plt.rcParamsDefault) # reset plot configurations\n",
        "  plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label=target_classes[0]+' vs Rest'+\" | AUC = %0.2f\" % auc[0])\n",
        "  plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label=target_classes[1]+' vs Rest'+\" | AUC = %0.2f\" % auc[1])\n",
        "  plt.plot(fpr[2], tpr[2], linestyle='--',color='red', label=target_classes[2]+' vs Rest'+\" | AUC = %0.2f\" % auc[2])\n",
        "  plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive rate')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.savefig(f\"{root_path}/Models_metrics{model_name}/ROC_AUC_{iteration}.pdf\", bbox_inches =\"tight\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kLrLqLCpcDg"
      },
      "outputs": [],
      "source": [
        "# only for binary classification\n",
        "def plot_ROC_AUC(y_true,  y_pred, auc_metric, iteration):\n",
        "  fpr, tpr, _ = roc_curve(y_true,  y_pred)\n",
        "  auc = roc_auc_score(y_true, y_pred)\n",
        "  auc_metric.append(auc)\n",
        "  \n",
        "  plt.rcParams.update(plt.rcParamsDefault) # reset plot configurations\n",
        "\n",
        "  # plot\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, color=\"darkorange\", lw=2, \n",
        "           label=\"AUC = %0.2f\" % auc)\n",
        "  plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.savefig(f\"{root_path}/Models_metrics{model_name}/ROC_AUC_{iteration}.pdf\", bbox_inches =\"tight\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFesglxUgrA_"
      },
      "source": [
        "Plot confusion matrix and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aKnB9qfo9q7"
      },
      "outputs": [],
      "source": [
        "def conf_matrix(y_true, y_pred, test_acc, iteration):\n",
        "  c_m = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "  # compute accuracy\n",
        "  test_acc.append(round(np.trace(c_m)/c_m.sum(), 4)*100)\n",
        "  print(\"Test accuracy for every iteration \", test_acc)\n",
        "\n",
        "  cm = c_m.astype('float') / c_m.sum(axis=1)[:,None] # normalize\n",
        "  cm = cm.round(2)\n",
        "  cm = pd.DataFrame(cm, index = target_classes, columns = target_classes)\n",
        "\n",
        "  #plot\n",
        "  plt.figure(figsize = (4,4))\n",
        "  sns.set(font_scale=1.4) # for label size\n",
        "  hm = sns.heatmap(cm, annot=True, cmap = \"Blues\", annot_kws={\"size\": 25}, cbar=False)\n",
        "  hm.set_xlabel(\"Predicted Labels\")\n",
        "  hm.set_ylabel(\"Actual Labels\")\n",
        "  plt.savefig(f\"{root_path}/Models_metrics{model_name}/conf_matrix_{iteration}.pdf\", bbox_inches =\"tight\")\n",
        "  plt.show()\n",
        "  return c_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGnLB2eBrCFf"
      },
      "source": [
        "Given a confusion matrix compute sensitivity and specificity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0CMFvJkgNhg"
      },
      "outputs": [],
      "source": [
        "def compute_sen_spec(cm, sen_metric, spec_metric):\n",
        "  sen = cm[1][1] / (cm[1][1]+cm[1][0])\n",
        "  spec = cm[0][0] / (cm[0][0]+cm[0][1])\n",
        "  sen_metric.append(sen)\n",
        "  spec_metric.append(spec)\n",
        "  print(\"sensitivity \", round(sen,4)*100, \" %\")\n",
        "  print(\"specificity \", round(spec,4)*100, \" %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgA_lkwDKVzw"
      },
      "source": [
        "Agloremation of all the metrics in one function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9wWYqWZFUuF"
      },
      "outputs": [],
      "source": [
        "def metrics(y_pred_orig, y_true, test_metrics, iteration):\n",
        "  # metrics: acc, confusion matrix, sen, spec, ROC, AUC\n",
        "  if nr_classes == 3:\n",
        "    y_pred = list(np.argmax(y_pred_orig, axis=1))\n",
        "    print(classification_report(y_true, y_pred, target_names=target_classes))\n",
        "    test_metrics['f1'].append(round(f1_score(y_true, y_pred), 2))\n",
        "    print(\"f1-score \", test_metrics['f1'])\n",
        "    conf_matrix(y_true, y_pred, test_metrics['acc'], iteration)\n",
        "    y_pred_orig = [item for sublist in y_pred_orig for item in sublist]\n",
        "    plot_ROC_AUC_multiclass(y_true,  y_pred_orig, iteration)  \n",
        "  else:\n",
        "    y_pred = list(np.argmax(y_pred_orig, axis=1))\n",
        "    print(classification_report(y_true, y_pred, target_names=target_classes))\n",
        "    test_metrics['f1'].append(round(f1_score(y_true, y_pred), 2))\n",
        "    print(\"f1-score \", test_metrics['f1'])\n",
        "    c_m = conf_matrix(y_true, y_pred, test_metrics['acc'], iteration)\n",
        "    compute_sen_spec(c_m, test_metrics['sen'], test_metrics['spec'])\n",
        "    plot_ROC_AUC(y_true, y_pred_orig[:,1], test_metrics['auc'], iteration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBmYqIJbUjoB"
      },
      "outputs": [],
      "source": [
        "def show_means_metrics(test_metric):\n",
        "  test_means = {'acc': {}, 'f1': {}, 'sen': {}, 'spec': {}, 'auc': {}}\n",
        "  test_means['acc']['avg'] = round(mean(test_metric['acc']),4)\n",
        "  test_means['acc']['std'] = round(stdev(test_metric['acc']), 4)\n",
        "  print(\"Mean test accuracy \", test_means['acc']['avg'])\n",
        "  print(\"Standard deviation accuracy \", test_means['acc']['std'])\n",
        "\n",
        "  test_means['f1']['avg'] = round(mean(test_metric['f1']), 4)\n",
        "  test_means['f1']['std'] = round(stdev(test_metric['f1']), 4)\n",
        "  print(\"Mean test f1_score \", test_means['f1']['avg'])\n",
        "  print(\"Standard deviation f1_score \", test_means['f1']['std'])\n",
        "\n",
        "  test_means['sen']['avg'] = round(mean(test_metric['sen']), 4)\n",
        "  test_means['sen']['std'] = round(stdev(test_metric['sen']), 4)\n",
        "  print(\"Mean test sensitivity \", test_means['sen']['avg'])\n",
        "  print(\"Standard deviation sensitivity \", test_means['sen']['std'])\n",
        "\n",
        "  test_means['spec']['avg'] = round(mean(test_metric['spec']), 4)\n",
        "  test_means['spec']['std'] = round(stdev(test_metric['spec']), 4)\n",
        "  print(\"Mean test specificity \", test_means['spec']['avg'])\n",
        "  print(\"Standard deviation specificity \", test_means['spec']['std'])\n",
        "\n",
        "  test_means['auc']['avg'] = round(mean(test_metric['auc']), 4)\n",
        "  test_means['auc']['std'] = round(stdev(test_metric['auc']), 4)\n",
        "  print(\"Mean test AUC \", test_means['auc']['avg'])\n",
        "  print(\"Standard deviation AUC \", test_means['auc']['std'])\n",
        "\n",
        "  return test_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrLT6YxmZ-9n"
      },
      "source": [
        "# Training parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ6gVcoNTGYp"
      },
      "source": [
        "Training of the netork with cross-validation. Several validations were made for different hyperparameters, like batch size, nr of layers, normalization block's momentum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le2uC81Sv0VV"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "params = {'dim': (128,128,60),\n",
        "          'batch_size': 16,\n",
        "          'n_classes': nr_classes,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': False}\n",
        "\n",
        "params_test = {'dim': (128,128,60),\n",
        "          'batch_size': 1,\n",
        "          'n_classes': nr_classes,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': False}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk95NyUXsFkW"
      },
      "source": [
        "Plots of accuracy and loss along epochs during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc7WN1O3z-uD"
      },
      "outputs": [],
      "source": [
        "def graph_accuracy_loss(history, iteration):\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['accuracy'], marker='o')\n",
        "  plt.plot(history.history['val_accuracy'], marker='o')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.ylim([0, 1])\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='lower right')\n",
        "  plt.grid()\n",
        "  plt.savefig(f\"{root_path}/Models_metrics{model_name}/accuracy_epochs_{iteration}.pdf\", bbox_inches =\"tight\")\n",
        "  plt.show()\n",
        "\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'], marker='o')\n",
        "  plt.plot(history.history['val_loss'], marker='o')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper right')\n",
        "  plt.grid()\n",
        "  plt.savefig(f\"{root_path}/Models_metrics{model_name}/loss_epochs_{iteration}.pdf\", bbox_inches =\"tight\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faaz3pNOKIv1"
      },
      "source": [
        "Train and validation accuracy average for a certain number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZlAtnYCjqQX"
      },
      "outputs": [],
      "source": [
        "def print_avg_acc(history, nr_epochs):\n",
        "  acc = np.array(history.history['accuracy'][-nr_epochs:]) * 100\n",
        "  avg_acc = mean(acc)\n",
        "\n",
        "  val_acc = np.array(history.history['val_accuracy'][-nr_epochs:]) * 100\n",
        "  avg_val_acc = mean(val_acc)\n",
        "  \n",
        "  print('Average Accuracy Train: %.2f, Validation: %.2f' % (avg_acc, avg_val_acc))\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbiuaIMnJ_jB"
      },
      "source": [
        "Train and validation accuracy standard deviation for a certain number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy9udM33mPE0"
      },
      "outputs": [],
      "source": [
        "def print_acc_std_dev(history, nr_epochs):\n",
        "  acc = np.array(history.history['accuracy'][-nr_epochs:]) * 100\n",
        "  var_acc = np.var(acc)\n",
        "  var_acc = math.sqrt(var_acc)\n",
        "\n",
        "  val_acc = np.array(history.history['val_accuracy'][-nr_epochs:]) * 100\n",
        "  var_val_acc = np.var(val_acc)\n",
        "  var_val_acc = math.sqrt(var_val_acc)\n",
        "\n",
        "  print('Accuracy Standard deviation Train: %.2f, Validation: %.2f' % (var_acc, var_val_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNyzOoXKQhcW"
      },
      "source": [
        "# Testing with cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A3qFTkypCAW"
      },
      "outputs": [],
      "source": [
        "test_metric = {\n",
        "  'acc': [],\n",
        "  'f1': [],\n",
        "  'sen': [],\n",
        "  'spec': [],\n",
        "  'auc': []}\n",
        "\n",
        "final_model = []\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# stratified k fold cross-validation with scans of the same subject in the same fold\n",
        "# split training and test set\n",
        "# these two sets do not contain overlapping subjects\n",
        "# these two sets have the same proportion of both classes\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=7)\n",
        "\n",
        "for iteration, (train, test) in enumerate(sgkf.split(scan_ids, labels_list, subject_id_list)):\n",
        "  print('Iteration number: ', iteration)\n",
        "  # simple early stopping\n",
        "  #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "  # to save best model\n",
        "  mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "\n",
        "  # obtain scans ID\n",
        "  train = [ scan_ids[index] for index in train ]\n",
        "  test = [ scan_ids[index] for index in test ]\n",
        "\n",
        "  verify_proportions(labels, train, test)\n",
        "\n",
        "  # create network\n",
        "  cbam_block.att_layer_nr = 0 # reinizialize the attention layer number\n",
        "  net = Resnet3DBuilder()\n",
        "  if nr_classes == 2:\n",
        "    model = net.build_resnet_18((128, 128, 60, 1), num_outputs=2)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "  elif nr_classes == 3:\n",
        "    model = net.build_resnet_18((128, 128, 60, 1), num_outputs=3)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "  np.random.shuffle(train)\n",
        "  np.random.shuffle(test)\n",
        "\n",
        "  # train validation split\n",
        "  train_labels_list = [ labels[id] for id in train ] # labels\n",
        "  train_subject_id_list = [ subject_id[id] for id in train  ] # scan's subject ID\n",
        "\n",
        "  splitter = StratifiedGroupKFold(n_splits=7, shuffle=True, random_state=7)\n",
        "  train_val_split = splitter.split(train, train_labels_list, train_subject_id_list)\n",
        "  subtrain_indx, val_indx = next(train_val_split)\n",
        "\n",
        "  subtrain = [ train[index] for index in subtrain_indx ]\n",
        "  val = [ train[index] for index in val_indx ]\n",
        "\n",
        "  verify_proportions(labels, subtrain, val)\n",
        "\n",
        "  # generators\n",
        "  training_generator = DataGenerator(subtrain, labels, **params)\n",
        "  validation_generator = DataGenerator(val, labels, **params)\n",
        "  test_generator = DataGenerator(test, labels, **params_test)\n",
        "\n",
        "  # class weights\n",
        "  class_weights = compute_class_weight('balanced', classes = np.unique(labels_list), y = [labels[i] for i in subtrain])\n",
        "  if nr_classes == 2:\n",
        "    class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
        "  elif nr_classes == 3:\n",
        "    class_weights = {0: class_weights[0], 1: class_weights[1], 2: class_weights[2]}\n",
        "  print(class_weights)\n",
        "\n",
        "  # train\n",
        "  history = model.fit(training_generator, validation_data=validation_generator, epochs = 50, class_weight=class_weights, callbacks=[mc])\n",
        "  graph_accuracy_loss(history, iteration) # plot acc and loss for each epoch\n",
        "  print_avg_acc(history, 20)\n",
        "  print_acc_std_dev(history, 20)\n",
        "\n",
        "  # test\n",
        "  print(\"TEST -----------------------------------------\")\n",
        "  y_true = [labels[i] for i in test]\n",
        "  final_model.append(load_model('best_model.h5', custom_objects={'att': att})) # load best model\n",
        "  y_pred = final_model[-1].predict(test_generator)\n",
        "  metrics(y_pred, y_true, test_metric, iteration)\n",
        "\n",
        "test_means = show_means_metrics(test_metric)\n",
        "\n",
        "end = time.time()\n",
        "elpased_time = end - start\n",
        "print(\"\\nExecution time \", timedelta(seconds=elpased_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE5GRTOm3bok"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGDlpnmvb8Ds"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcECoWyfslHj"
      },
      "outputs": [],
      "source": [
        "# save the best model on the test data to Google Drive\n",
        "max_value = max(test_metric['acc'])\n",
        "max_index = test_metric['acc'].index(max_value)\n",
        "model = final_model[max_index]\n",
        "model.save(root_path+'/Saved_Models'+ model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ITSGZA_b5HW"
      },
      "source": [
        "Save model metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXDF2hTrZ5TN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(root_path+'/Models_metrics'+ model_name+'/test_metrics.json', 'w') as test_metrics_file:\n",
        "     test_metrics_file.write(json.dumps(test_metric))\n",
        "\n",
        "with open(root_path+'/Models_metrics'+ model_name+'/test_means.json', 'w') as test_means_file:\n",
        "     test_means_file.write(json.dumps(test_means))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4CK4pNOKWsm"
      },
      "source": [
        "Save model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQNsy_dGZKOq"
      },
      "outputs": [],
      "source": [
        "from contextlib import redirect_stdout\n",
        "\n",
        "with open(root_path+'/Models_metrics'+ model_name+'/model_summary.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA0IwNp7KYwQ"
      },
      "source": [
        "Save model diagram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPlAF11_3y8J"
      },
      "outputs": [],
      "source": [
        "plot_model(model, to_file=root_path+'/Models_metrics'+ model_name+'/plot_model.png', show_shapes=True, show_layer_names=True, show_layer_activations=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIks7IwawPva"
      },
      "source": [
        "# Visualization Saliency and Attention Maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8xtR82EbhRl"
      },
      "source": [
        "#### Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFEMzyq-W_GP"
      },
      "source": [
        "Plot a slice of a normalized PET scan "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ0DvdzGW-UE"
      },
      "outputs": [],
      "source": [
        "def show_normalized_scan(ID, slice_nr):\n",
        "  scan = np.load(root_path + '/PETs_numpy/normalized/' + str(ID) + '.npy')\n",
        "  show_scan_plot(scan, slice_nr)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggk3rE2jW1dH"
      },
      "source": [
        "Plot a slice of a not normalized PET scan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsLtb_fpWxIp"
      },
      "outputs": [],
      "source": [
        "def show_not_normalized_scan(ID, slice_nr):\n",
        "  scan = np.load(root_path + '/PETs_numpy/not_normalized/' + str(ID) + '.npy')\n",
        "  show_scan_plot(scan, slice_nr)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXmBIOi2NMsh"
      },
      "source": [
        "Plot a slice of the saliency map of a PET scan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3PzQm1tw5nR"
      },
      "outputs": [],
      "source": [
        "def show_scan_saliency_map(ID, slice_nr, type):\n",
        "  att_map = np.load(root_path + '/attention_maps/'+type+'/'+ str(ID) + '.npy')\n",
        "  show_scan_plot(att_map, slice_nr)\n",
        "  plt.clim(0,1)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4qrJcfYasDk"
      },
      "source": [
        "Plot a slice of a PET scan with the saliency map created by the doctor on top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooKU3Esqaj1g"
      },
      "outputs": [],
      "source": [
        "def show_scan_saliency_map_ontop(ID, slice_nr, type):\n",
        "  scan = np.load(root_path + '/PETs_numpy/not_normalized/' + str(ID) + '.npy')\n",
        "  one_slice_2d = scan[:,:,slice_nr]\n",
        "  plt.imshow(one_slice_2d, cmap='gray', zorder=0)\n",
        "\n",
        "  att_map = np.load(root_path + '/attention_maps/'+type+'/'+ str(ID) + '.npy')\n",
        "  one_slice_2d = att_map[:,:,slice_nr]\n",
        "  plt.imshow(one_slice_2d, cmap='jet', alpha=0.4, zorder=10)\n",
        "  plt.clim(0,1)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9OilcAzXkhg"
      },
      "source": [
        "Plot a fixed saliency map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVHzVh6yXL5-"
      },
      "outputs": [],
      "source": [
        "def show_scan_fixed_saliency_map(slice_nr, type, target_classes):\n",
        "  c = \"\".join('_'+i for i in target_classes)\n",
        "\n",
        "  fix_att_map = np.load(root_path + '/attention_maps/Fixed_attention/'+type+ c + '.npy')\n",
        "  show_scan_plot(fix_att_map, slice_nr)\n",
        "  plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEInwEb-bbXG"
      },
      "source": [
        "Plot a fixed saliency map on top of a slice of a PET scan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fAzGgVpbXp5"
      },
      "outputs": [],
      "source": [
        "def show_scan_fixed_saliency_map_ontop(slice_nr, type, target_classes):\n",
        "  # retrieve random scan\n",
        "  scan = np.load(root_path + '/PETs_numpy/not_normalized/' + str(25) + '.npy')\n",
        "  one_slice_2d = scan[:,:,slice_nr]\n",
        "  plt.imshow(one_slice_2d, cmap='gray', zorder=0)\n",
        "\n",
        "  c = \"\".join('_'+i for i in target_classes)\n",
        "  fix_att_map = np.load(root_path + '/attention_maps/Fixed_attention/'+type+ c + '.npy')\n",
        "  one_slice_2d = fix_att_map[:,:,slice_nr]\n",
        "  plt.imshow(one_slice_2d, cmap='jet', alpha=0.4, zorder=10)\n",
        "  plt.clim(0,1)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivEnfPBKYzTL"
      },
      "source": [
        "Plot a slice of an attention map created by the model and resized to original dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFgYOPFH1k9D"
      },
      "outputs": [],
      "source": [
        "def show_model_attention_map(ID, slice_nr, CNN_model, att_layer_nr):\n",
        "  x_test = np.zeros((1,128,128,60,1))\n",
        "  x_test[0,:,:,:,0] = np.load(root_path + '/PETs_numpy/normalized/' + str(ID) + '.npy')\n",
        "\n",
        "  layer_name = 'att_'+str(att_layer_nr)\n",
        "  intermediate_layer_model = Model(inputs=CNN_model.input,\n",
        "                                        outputs=CNN_model.get_layer(layer_name).output)\n",
        "  intermediate_output = intermediate_layer_model(x_test)\n",
        "  #inter_out = np.where(intermediate_output[0,:,:,:,0] < 0, 0, intermediate_output[0,:,:,:,0])\n",
        "\n",
        "  size_1 = intermediate_output.shape[1]\n",
        "  size_2 = intermediate_output.shape[2]\n",
        "  size_3 = intermediate_output.shape[3]\n",
        "\n",
        "  print(\"Attention map with real dimensions\")\n",
        "  show_scan_plot(intermediate_output[0,:,:,:,0], int(slice_nr*size_3/60))\n",
        "  plt.clim(0,1)\n",
        "  plt.show()\n",
        "  print(np.amax(intermediate_output[0,:,:,:,0]))\n",
        "  print(np.amin(intermediate_output[0,:,:,:,0]))\n",
        "\n",
        "  print(\"Resized - Real dimensions of attention map \", size_1, size_2, size_3)\n",
        "\n",
        "  res = zoom(np.array(intermediate_output[0,:,:,:,0]), (128/size_1, 128/size_2, 60/size_3)) # determinar se este é o melhor resize\n",
        "  \n",
        "  one_slice_2d = res[:,:,slice_nr]\n",
        "  plt.imshow(one_slice_2d, cmap='jet')\n",
        "  plt.clim(0,1)\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  print(np.amax(res))\n",
        "  print(np.amin(res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxCZmFvpY9rR"
      },
      "source": [
        "Scan with the attention map created by the model on top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2vCwyjXsALC"
      },
      "outputs": [],
      "source": [
        "def show_scan_model_attention_ontop(ID, slice_nr, CNN_model, att_layer_nr):\n",
        "  scan = np.load(root_path + '/PETs_numpy/not_normalized/' + str(ID) + '.npy')\n",
        "  one_slice_2d = scan[:,:,slice_nr]\n",
        "  plt.imshow(one_slice_2d, cmap='gray', zorder=0)\n",
        "\n",
        "  x_test = np.zeros((1,128,128,60,1))\n",
        "  x_test[0,:,:,:,0] = np.load(root_path + '/PETs_numpy/normalized/' + str(ID) + '.npy')\n",
        "\n",
        "  layer_name = 'att_'+str(att_layer_nr)\n",
        "  intermediate_layer_model = Model(inputs=CNN_model.input,\n",
        "                                        outputs=CNN_model.get_layer(layer_name).output)\n",
        "  intermediate_output = intermediate_layer_model(x_test)\n",
        "\n",
        "  size_1 = intermediate_output.shape[1]\n",
        "  size_2 = intermediate_output.shape[2]\n",
        "  size_3 = intermediate_output.shape[3]\n",
        "  print(\"Real dimensions of attention map \", size_1, size_2, size_3)\n",
        "\n",
        "  res = zoom(np.array(intermediate_output[0,:,:,:,0]), (128/size_1, 128/size_2, 60/size_3)) # determinar se este é o melhor resize\n",
        "\n",
        "  one_slice_2d = res[:,:,slice_nr]\n",
        "  plt.imshow(one_slice_2d, cmap='jet', alpha=0.4, zorder=10)\n",
        "  plt.clim(0,1)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg7N1R0zWN0S"
      },
      "source": [
        "Return the row index of a scan in its dataframe given the scan ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uxUcHBSPGPG"
      },
      "outputs": [],
      "source": [
        "def get_scan_index_in_Dataframe(allData1, allData2, allData3, scan_id):\n",
        "  value1 = allData1.index[allData1['Scan ID'] == scan_id]\n",
        "  value2 = allData2.index[allData2['Scan ID'] == scan_id]\n",
        "  value3 = allData3.index[allData3['Scan ID'] == scan_id]\n",
        "  print(value1, value2, value3)\n",
        "  if len(value1) == 1:\n",
        "    return value1[0]\n",
        "  elif len(value2) == 1:\n",
        "    return value2[0]\n",
        "  elif len(value3) == 1:\n",
        "    return value3[0]\n",
        "  else:\n",
        "    raise Exception(\"Sorry, there is no scan with that ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcrkm2KwbnqH"
      },
      "source": [
        "#### Examples Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYublSN4qkeF"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model1 = keras.models.load_model(root_path+'/Saved_Models/'+ model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qcgDq3Cyg6R"
      },
      "source": [
        "Load Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J4kFKkRygKG"
      },
      "outputs": [],
      "source": [
        "nc_allData = pd.read_pickle(\"/content/drive/My Drive/dataset/pandas_dataframes/nc_allData.pkl\")\n",
        "mci_allData = pd.read_pickle(\"/content/drive/My Drive/dataset/pandas_dataframes/mci_allData.pkl\")\n",
        "ad_allData = pd.read_pickle(\"/content/drive/My Drive/dataset/pandas_dataframes/ad_allData.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u56R06_rsn0Y"
      },
      "source": [
        "Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70bmMhD2yKn3"
      },
      "outputs": [],
      "source": [
        "ID = 245\n",
        "slice_nr = 25\n",
        "type = \"Location_based\"\n",
        "target_classes = ['NC', 'AD']\n",
        "# index = get_scan_index_in_Dataframe(nc_allData, mci_allData, ad_allData, ID)\n",
        "# show_normalized_scan(ID, slice_nr)\n",
        "# show_not_normalized_scan(ID, slice_nr)\n",
        "# show_scan_with_fixations(nc_allData, slice_nr=slice_nr, scan_index=index, save=\"not save\")\n",
        "# plt.show()\n",
        "# show_scan_saliency_map(ID, slice_nr, type)\n",
        "# show_scan_saliency_map_ontop(ID, slice_nr, type)\n",
        "# show_scan_fixed_saliency_map(slice_nr, type, target_classes)\n",
        "# show_scan_fixed_saliency_map_ontop(slice_nr, type, target_classes)\n",
        "# show_model_attention_map(ID, slice_nr, model1, 0)\n",
        "# show_scan_model_attention_ontop(ID, slice_nr, model1, 0)\n",
        "# show_model_attention_map(ID, slice_nr, model1, 1)\n",
        "# show_scan_model_attention_ontop(ID, slice_nr, model1, 1)\n",
        "# show_model_attention_map(ID, slice_nr, model1, 7)\n",
        "# show_scan_model_attention_ontop(ID, slice_nr, model1, 7)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "lJOYzMvBQ3lZ",
        "lok_sHRz4kDz",
        "sT0QCACvqeGx",
        "DIks7IwawPva",
        "G8xtR82EbhRl"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}